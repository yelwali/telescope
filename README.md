# üè• AI for Gamma Telescope Classification
Ce projet vise √† classer les √©v√©nements d√©tect√©s par un t√©lescope gamma en utilisant diff√©rentes techniques d'apprentissage automatique. L'objectif est de distinguer les signaux gamma (classe positive) du bruit de fond (classe n√©gative) avec une pr√©cision √©lev√©e.

## Pr√©-traitement des donn√©es

1. **Normalisation des donn√©es** : 
   - Les donn√©es num√©riques ont √©t√© normalis√©es en utilisant le `RobustScaler` pour r√©duire l'effet des valeurs aberrantes.
   - Une transformation de normalisation suppl√©mentaire a √©t√© appliqu√©e avec `PowerTransformer` (m√©thode Yeo-Johnson) pour stabiliser la variance et rendre les donn√©es plus gaussiennes.

2. **√âquilibrage des classes** :
   - Le d√©s√©quilibre des classes a √©t√© corrig√© en utilisant la technique **SMOTE** (Synthetic Minority Over-sampling Technique). Cela permet de g√©n√©rer des √©chantillons synth√©tiques pour la classe minoritaire, am√©liorant ainsi la performance des mod√®les sur cette classe.

## Mod√®les utilis√©s et r√©sultats

Plusieurs mod√®les d'apprentissage automatique ont √©t√© entra√Æn√©s et √©valu√©s sur le dataset. Voici un r√©sum√© de leurs performances :

| Mod√®le                        | Accuracy | Precision | Recall |
|-------------------------------|----------|-----------|--------|
| Logistic Regression           | 0.800357 | 0.807610  | 0.788597 |
| Decision Tree                 | 0.835104 | 0.864331  | 0.795166 |
| Extreme Gradient Boosting     | 0.885907 | 0.903201  | 0.864497 |
| Gradient Boosting             | 0.814426 | 0.811462  | 0.819330 |
| Random Forest                 | 0.895921 | 0.905862  | 0.883715 |
| Support Vector Machine (SVM)  | 0.895557 | 0.879117  | 0.917124 |

### Analyse des r√©sultats
- **Random Forest** et **SVM** ont obtenu les meilleures performances en termes d'**Accuracy** et de **Recall**.
- **Extreme Gradient Boosting** a √©galement montr√© des r√©sultats comp√©titifs, avec une pr√©cision √©lev√©e.
- **Logistic Regression** et **Gradient Boosting** ont des performances l√©g√®rement inf√©rieures mais restent acceptables.

## Conclusion
Le mod√®le **Random Forest** semble √™tre le meilleur choix pour ce projet, offrant un bon √©quilibre entre pr√©cision et rappel. Cependant, le **SVM** pourrait √™tre pr√©f√©r√© si le rappel est une m√©trique plus critique pour l'application.

## Prochaines √©tapes
- Explorer l'optimisation des hyperparam√®tres pour am√©liorer davantage les performances.
- Tester des architectures de r√©seaux de neurones pour comparer avec les mod√®les traditionnels.
- D√©ployer le mod√®le s√©lectionn√© dans un environnement de production pour une classification en temps r√©el.

## D√©pendances
- Python 3.x
- Biblioth√®ques : `scikit-learn`, `imbalanced-learn`, `pandas`, `numpy`, `xgboost`

## Installation
1. Cloner le d√©p√¥t :
   ```bash
   git clone https://github.com/votre-utilisateur/ai-gamma-telescope.git

```

## Utilisation
1. Charger les donn√©es et appliquer les techniques de pr√©traitement.
2. Entra√Æner les mod√®les et √©valuer leurs performances.
3. Comparer les r√©sultats pour choisir le mod√®le optimal.

## Auteurs
Ce projet a √©t√© r√©alis√© dans le cadre d'un projet de fin d'√©tudes sous la supervision de **M. Abdelkarim El Mouatasim**.

## Licence
Ce projet est sous licence MIT - voir le fichier LICENSE pour plus de d√©tails.



